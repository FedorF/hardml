{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание считается успешно выполненным при получении скора RMSE ≤ 2.45⋅10e6 \n",
    "\n",
    "В итоге помог стекинг бустингов, и усреднение многих сабмитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from hyperopt import hp\n",
    "import hyperopt as hopt\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacking(BaseEstimator, ClassifierMixin):  \n",
    "\n",
    "    def __init__(self, models, ens_model):\n",
    "        self.models = models\n",
    "        self.ens_model = ens_model\n",
    "        self.n = len(models)\n",
    "        self.valid = None\n",
    "        \n",
    "    def fit(self, X, y=None, p=0.25, cv=3, err=0.001, random_state=None):\n",
    "        if p > 0:\n",
    "            # разбиение на обучение моделей и метамодели\n",
    "            train, valid, y_train, y_valid = train_test_split(X, y, test_size=p, random_state=random_state)\n",
    "            \n",
    "            # заполнение матрицы для обучения метамодели\n",
    "            self.valid = np.zeros((valid.shape[0], self.n))\n",
    "            for t, clf in tqdm(enumerate(self.models)):\n",
    "                clf.fit(train, y_train)\n",
    "                self.valid[:, t] = clf.predict(valid)\n",
    "                \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y_valid)\n",
    "            \n",
    "        else:\n",
    "            # для регуляризации - берём случайные добавки\n",
    "            self.valid = err*np.random.randn(X.shape[0], self.n)\n",
    "            \n",
    "            for t, clf in tqdm(enumerate(self.models)):\n",
    "                # oob-ответы алгоритмов\n",
    "                self.valid[:, t] += cross_val_predict(clf, X, y, cv=cv, method='predict')\n",
    "                # но сам алгоритм надо настроить\n",
    "                clf.fit(X, y)\n",
    "            \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y)    \n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        X_meta = np.zeros((X.shape[0], self.n))\n",
    "        \n",
    "        for t, clf in tqdm(enumerate(self.models)):\n",
    "            X_meta[:, t] = clf.predict(X)\n",
    "        \n",
    "        a = self.ens_model.predict(X_meta)\n",
    "        \n",
    "        return (a)\n",
    "\n",
    "\n",
    "class Meaning:\n",
    "    def __init__(self, n_models, params, cat_features, param_grid, num_it):\n",
    "        self.param_grid = param_grid\n",
    "        self.num_it = num_it\n",
    "        self.cat_features = cat_features\n",
    "        self.params = params\n",
    "        self.n_models = n_models\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        for i in tqdm(range(self.n_models)):\n",
    "            if self.num_it > 1:\n",
    "                params = self._find_best_params(X_train, y_train, i)\n",
    "                print(params)\n",
    "            else:\n",
    "                params = self.params\n",
    "            model = LGBMRegressor(random_state=100*i, **params)\n",
    "            model.fit(X_train, y_train)\n",
    "                \n",
    "            self.models.append(model)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def _find_best_params(self, X_train, y_train, i) -> dict:\n",
    "        \"\"\"Use hyperopt to find optimal model hyper-parameters.\"\"\"\n",
    "\n",
    "        def objective(pars):\n",
    "            model = LGBMRegressor(random_state=100*i, **pars)\n",
    "            score = cross_val_score(model, X_train, y_train, cv=3, scoring=rmse).mean()\n",
    "\n",
    "            return score\n",
    "\n",
    "        best_params = hopt.fmin(fn=objective, space=self.param_grid, algo=hopt.tpe.suggest, max_evals=self.num_it)\n",
    "\n",
    "        return best_params\n",
    "            \n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        y_pred = np.zeros((len(X_test), self.n_models))\n",
    "\n",
    "        for i, model in tqdm(enumerate(self.models)): \n",
    "            y_pred[:, i] = model.predict(X_test)\n",
    "            \n",
    "        return np.mean(y_pred, axis=1)          \n",
    "\n",
    "\n",
    "def plot_ecdf(data):\n",
    "    x, y = sorted(data), np.arange(1, len(data)+1) / len(data)\n",
    "    plt.figure()\n",
    "    plt.scatter(x, y)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def bias(true, pred):\n",
    "    return (pred - true).sum() / true.sum()\n",
    "\n",
    "\n",
    "def mean_delta(true, pred):\n",
    "    return (pred - true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'full_sq', \n",
    "    'full_sq_bins', \n",
    "    'life_sq', \n",
    "    'life_sq_bins', \n",
    "    'kitch_sq', \n",
    "    'kitch_sq_bins',\n",
    "    'some_extra_sqr',\n",
    "    'ratio_life_dash_full_sq', \n",
    "    'ration_kitchen_dash_full_sq',\n",
    "    'floor', \n",
    "    'floor_bins',\n",
    "    'max_floor',\n",
    "    'max_floor_bins',\n",
    "    'material',\n",
    "    'num_room', \n",
    "    'apartment condition',\n",
    "    'sub_area',\n",
    "    'sub_area_bins',\n",
    "    'population', \n",
    "    'indust_part',\n",
    "    'preschool_facilities',\n",
    "    'school_facilities', \n",
    "    'hospital_beds_raion',\n",
    "    'healthcare_facilities',\n",
    "    'university_num', \n",
    "    'sport_objects_facilities',\n",
    "    'additional_education_facilities',\n",
    "    'culture_objects_facilities',\n",
    "    'shopping_centers_facilities',\n",
    "    'office_num', \n",
    "    'green_part', \n",
    "    'prom_part',\n",
    "    'cafe_count', \n",
    "    'church_facilities', \n",
    "    'mosque',\n",
    "    'leisure_facilities',\n",
    "    'year',\n",
    "    'month',\n",
    "    'week_of_year', \n",
    "    'day_of_week',\n",
    "    'timestamp_int', \n",
    "    'build_year',\n",
    "    'age', \n",
    "]\n",
    "\n",
    "cat_features = [\n",
    "       'material', 'apartment condition', 'full_sq_bins',\n",
    "       'year', 'month', 'week_of_year', 'day_of_week',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем данные в соответствующие датафреймы\n",
    "\n",
    "train_main_df = pd.read_csv('./data_hw/HW_train_main_data.csv')\n",
    "train_additional_df = pd.read_csv('./data_hw/HW_train_additional_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_main_df = pd.read_csv('./data_hw/HW_test_main_data.csv')\n",
    "test_additional_df = pd.read_csv('./data_hw/HW_test_additional_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим дополнительные данные\n",
    "\n",
    "whole_train_df = train_main_df.merge(train_additional_df, how='left', on='id')\n",
    "whole_test_df = test_main_df.merge(test_additional_df, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df):   \n",
    "    bins = [0, 20, 30, 40, 50, 70, 80, 90, 100, 150, 200, 250, 375, 500, 10000]\n",
    "    df['full_sq_bins'] = np.searchsorted(bins, df['full_sq'].values)\n",
    "    \n",
    "    bins = [0, 20, 30, 40, 50, 100, 150, 201, 400, 500, 10000]\n",
    "    df['life_sq_bins'] = np.searchsorted(bins, df['life_sq'].values)\n",
    "\n",
    "    bins = [0, 5, 10, 15, 20, 40, 50, 100]\n",
    "    df['floor_bins'] = np.searchsorted(bins, df['floor'].values)\n",
    "    \n",
    "    bins = [0, 5, 9, 13, 15, 20, 35, 42, 50, 200]\n",
    "    df['max_floor_bins'] = np.searchsorted(bins, df['max_floor'].values)\n",
    "    \n",
    "    bins = [0, 2, 5, 10, 15, 45, 70, 80, 100, 1000]\n",
    "    df['kitch_sq_bins'] = np.searchsorted(bins, df['kitch_sq'].values)\n",
    "    \n",
    "    bins = [0, 20, 40, 60, 70, 90, 100, 110, 1000]\n",
    "    df['sub_area_bins'] = np.searchsorted(bins, df['sub_area'].values)\n",
    "    \n",
    "    # конвертируем колонку в datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  \n",
    "    \n",
    "    # добавим дополнительные столбцы на основе имеющейся даты\n",
    "    # get year  \n",
    "    df['year'] = df.timestamp.dt.year\n",
    "\n",
    "    # get month of year\n",
    "    df['month'] = df.timestamp.dt.month\n",
    "\n",
    "    # get day of week\n",
    "    df['week_of_year'] = df.timestamp.dt.weekofyear\n",
    "\n",
    "    # get week of the year\n",
    "    df['day_of_week'] = df.timestamp.dt.weekday\n",
    "\n",
    "    df['timestamp_int'] = df.timestamp.astype(int)\n",
    "    \n",
    "    # создадим столбец для месяца года\n",
    "    df['year_month'] = df['year'].astype(str) + '_' + df['month'].astype(str)  \n",
    "\n",
    "    # вспомним, что цена сильно зависит от площади квартиры, на основе этих данных\n",
    "    # добавим столбцы для отношения площадей\n",
    "    df[\"ratio_life_dash_full_sq\"] = np.where(df[\"full_sq\"] > 0, df[\"life_sq\"] / df[\"full_sq\"], -99)\n",
    "    df[\"ration_kitchen_dash_full_sq\"] = np.where(df[\"full_sq\"] > 0, df[\"kitch_sq\"] / df[\"full_sq\"], -99)\n",
    "\n",
    "    # добавим воздраст здания\n",
    "    df['age'] = df[\"build_year\"] - df['year']\n",
    "\n",
    "    # добавим разность между общей и жилой площадью квартиры\n",
    "    df['some_extra_sqr'] = df[\"full_sq\"] - df[\"life_sq\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_nans(df):\n",
    "    df.loc[df['life_sq'] == 0, 'life_sq'] = -99\n",
    "    df.loc[df['floor'] == 0, 'floor'] = -99\n",
    "    df.loc[df['max_floor'] == 0, 'max_floor'] = -99\n",
    "    df.loc[df['build_year'] <= 1900, 'build_year'] = -99\n",
    "    df.loc[df['num_room'] == 0, 'num_room'] = -99\n",
    "    df.loc[df['kitch_sq'] == 0, 'kitch_sq'] = -99\n",
    "    df.loc[df['some_extra_sqr'] < 0, 'some_extra_sqr'] = -99\n",
    "    df.loc[df['age'] < 0, 'age'] = -99\n",
    "    \n",
    "    df = df.fillna(-99)\n",
    "      \n",
    "    return df\n",
    "\n",
    "def change_types(df):\n",
    "    df['material'] = df['material'].astype(int)\n",
    "    df['apartment condition'] = df['apartment condition'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clip_dataset(cols, test, train):\n",
    "    new_train = train.copy()\n",
    "    for feat in cols:\n",
    "        f_min = test[feat].min()\n",
    "        f_max = test[feat].max()\n",
    "        new_train[feat] = new_train[feat].values.clip(f_min, f_max)\n",
    "\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление выброса\n",
    "\n",
    "whole_train_df = whole_train_df.loc[~whole_train_df.id.isin([85073, 67278])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Явно ошибочные значения\n",
    "\n",
    "whole_train_df.loc[whole_train_df.id == 28125, 'build_year'] = whole_train_df.loc[whole_train_df.id == 28125, 'kitch_sq']\n",
    "whole_train_df.loc[whole_train_df.kitch_sq > 1500, 'kitch_sq'] = 0\n",
    "\n",
    "whole_train_df.loc[whole_train_df.build_year == 20052009.0, 'build_year'] = 2007.0\n",
    "whole_train_df.loc[whole_train_df.build_year == 4965.0, 'build_year'] = 1965.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена выбросов в kitch_sq, floor, max_floor, num_room\n",
    "\n",
    "max_kitch_sq = whole_train_df.kitch_sq.max()\n",
    "whole_train_df.loc[whole_train_df.kitch_sq == max_kitch_sq, 'kitch_sq'] = max_kitch_sq / 100\n",
    "\n",
    "max_floor = whole_train_df.floor.max()\n",
    "whole_train_df.loc[whole_train_df.floor == max_floor, 'floor'] = max_floor / 10\n",
    "\n",
    "max_floor = whole_train_df.max_floor.max()\n",
    "whole_train_df.loc[whole_train_df.max_floor == max_floor, 'max_floor'] = max_floor / 10\n",
    "\n",
    "whole_train_df.loc[whole_train_df.max_floor == 99, 'max_floor'] = 0\n",
    "whole_train_df.loc[whole_train_df.num_room >= 10, 'num_room'] = 0\n",
    "whole_train_df.loc[whole_train_df.kitch_sq >= 100, 'kitch_sq'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена выброса в full_sq\n",
    "\n",
    "full_sq_max = whole_train_df.full_sq.max()\n",
    "whole_train_df.loc[whole_train_df.full_sq == full_sq_max, 'full_sq'] = full_sq_max / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена выбросов в life_sq и full_sq\n",
    "\n",
    "ids = [37439, 68638, 52414, 32115, 90717, 13539, 51155, 32184, 73754, 89638, 20359]\n",
    "whole_train_df.loc[whole_train_df.id.isin(ids), 'life_sq'] = whole_train_df.loc[whole_train_df.id.isin(ids), 'life_sq'] / 10\n",
    "\n",
    "ids=[91769, 52414, 32115, 49518, 21211, 11221, 41202, 61536,11965, 95936,71405,73754,20359]\n",
    "whole_train_df.loc[whole_train_df.id.isin(ids), 'full_sq'] = whole_train_df.loc[whole_train_df.id.isin(ids), 'full_sq'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена выброса в life_sq\n",
    "\n",
    "whole_test_df.loc[whole_test_df.id == 71980, 'life_sq'] = whole_test_df.loc[whole_test_df.id == 71980, 'life_sq'] / 10\n",
    "whole_test_df.loc[whole_test_df.id == 24392, 'life_sq'] = whole_test_df.loc[whole_test_df.id == 24392, 'life_sq'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем признаки\n",
    "\n",
    "whole_train_df = change_types(fill_nans(prepare_features(whole_train_df)))\n",
    "whole_test_df = change_types(fill_nans(prepare_features(whole_test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем удалить выбросы\n",
    "\n",
    "price_max = np.quantile(whole_train_df['price'].values, .97)\n",
    "price_min = np.quantile(whole_train_df['price'].values, .0)\n",
    "\n",
    "whole_train_df['price_lim'] = whole_train_df['price'].values.clip(price_min, price_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: 19428 df_val: 9570\n"
     ]
    }
   ],
   "source": [
    "# Валидационный фолд\n",
    "\n",
    "df_train, df_val, y_train, y_val = train_test_split(\n",
    "    whole_train_df, whole_train_df.price,\n",
    "    test_size=.33,\n",
    "    random_state=42,\n",
    ")\n",
    "print(f'df_train: {len(df_train)} df_val: {len(df_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19428, 44)\n"
     ]
    }
   ],
   "source": [
    "# Полный датасет\n",
    "\n",
    "X_train, y_train = df_train[features], df_train['price']\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1, # 0.1\n",
    "    'num_leaves': 25, # 31\n",
    "    'max_depth': -1, # -1\n",
    "    'min_child_samples': 20, # 20\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'n_estimators': 121, # 100\n",
    "}\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': .1,\n",
    "    'max_depth': -1,\n",
    "    'n_estimators': 70 + hp.randint('n_estimators', 131),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.2, 0.9),\n",
    "    'subsample': hp.uniform('subsample', 0.2, 0.9),\n",
    "    'num_leaves': 10 + hp.randint('num_leaves', 40),\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(**params)\n",
    "rmse = make_scorer(mean_squared_error, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2828696\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(model, X_train, y_train, cv=5, scoring=rmse).mean()\n",
    "print(f'RMSE: {round(score)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "meaning = Meaning(100, params, cat_features, param_grid, -1)\n",
    "meaning.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:06, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2679095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = meaning.predict(df_val[features])\n",
    "score = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "print(f'RMSE: {round(score)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'full_sq', \n",
    "    'full_sq_bins', \n",
    "    'life_sq', \n",
    "    'life_sq_bins', \n",
    "    'kitch_sq', \n",
    "    'kitch_sq_bins',\n",
    "    'some_extra_sqr',\n",
    "    'ratio_life_dash_full_sq', \n",
    "    'ration_kitchen_dash_full_sq',\n",
    "    'floor',\n",
    "    'floor_bins',\n",
    "    'max_floor',\n",
    "    'max_floor_bins',\n",
    "    'material',\n",
    "    'num_room', \n",
    "    'apartment condition',\n",
    "    'sub_area',\n",
    "    'sub_area_bins',\n",
    "    'population', \n",
    "    'indust_part',\n",
    "    'preschool_facilities',\n",
    "    'school_facilities', \n",
    "    'hospital_beds_raion',\n",
    "    'healthcare_facilities',\n",
    "    'university_num', \n",
    "    'sport_objects_facilities',\n",
    "    'additional_education_facilities',\n",
    "    'culture_objects_facilities',\n",
    "    'shopping_centers_facilities',\n",
    "    'office_num', \n",
    "    'green_part', \n",
    "    'prom_part',\n",
    "    'cafe_count', \n",
    "    'church_facilities', \n",
    "    'mosque',\n",
    "    'leisure_facilities',\n",
    "    'year',\n",
    "    'month',\n",
    "    'week_of_year', \n",
    "    'day_of_week',\n",
    "    'timestamp_int', \n",
    "    'build_year',\n",
    "    'age', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [LGBMRegressor(**\n",
    "                            {\n",
    "                            'learning_rate': 0.1,\n",
    "                            'num_leaves': np.random.randint(5, 32),\n",
    "                            'max_depth': np.random.randint(5, 32),\n",
    "                            'subsample': max(0.1, np.random.rand(1)[0]),\n",
    "                            'colsample_bytree': max(0.1, np.random.rand(1)[0]),\n",
    "                            'n_estimators': np.random.randint(50, 250),\n",
    "                            }) for i in range(20)\n",
    "             ]\n",
    "\n",
    "ens_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [01:00,  3.02s/it]\n",
      "20it [00:00, 64.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 1.17 s, total: 2min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stacking = Stacking(predictors, ens_model)\n",
    "stacking.fit(whole_train_df[features], whole_train_df.price, p=0, cv=3, random_state=42)\n",
    "\n",
    "y_test_pred = stacking.predict(whole_test_df[features])\n",
    "test_main_df['predicted_price'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_main_df[['id', 'predicted_price']].to_csv('./data_hw/submit_stacking.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}